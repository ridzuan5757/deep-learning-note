\section{Chapter 1}

\subsection{Donald Hebb} 
Organization of behaviour - 1949 learning mechanism:
\begin{itemize}
	\item When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as on of the cells firing B, is increased.
	\item As A repeatedly excites B, its ability to excite B improves.
	\item Neuron that fire together wire together.
\end{itemize}

\subsection{Hebbian Learning}
\begin{itemize}
	\item If neuron $x$ repeatedly triggers neuron y, the synaptic knob connecting $x$ to $y$ get larger.
	\item In mathematical model:
	\[ w_{xy} = w_{xy} + \eta xy \]
	\item Weight of the connection from input neuron $x$ to output neuron $y$.
	\item This simple formula is actually the basis of many learning algorithms in machine learning.
\end{itemize}

This idea however is fundamentally unstable:
\begin{itemize}
	\item Stringer connections will enforce themselves.
	\item No notion of "competition".
	\item No \textit{reduction} in weights.
	\item Learning is unbounded.p
\end{itemize}

People came up with all kinds of modifications for it to try to make it more stable:
\begin{itemize}
	\item Allowing for weight normalization.
	\item Forgetting
\end{itemize}
This lead to the Generalized Hebbian learning, aka Sanger's rule where the contribution of input is \textit{incrementally distributed} over multiple outputs.
\[ w_{ij} = w_{ij} + \eta y_j\left( x_i -	\sum_{k=1}^{j}	w_{ik}y_k																									\right) \]

\subsection{A better model}
Frank Rosenblatt
\begin{itemize}
	\item Psychologist, Logician
	\item Inventor of the solution to everything, aka Perceptron
\end{itemize}

\paragraph{Original perceptron model}
Consider the eye structure:
\begin{itemize}
	\item Groups of sensors on retina combine into cells in association in the \textbf{projection area}.
	\item Groups of \textbf{projection area} combine into Association cells in \textbf{association area}.
	\item Signals from \textbf{association area} cells combine into response cell \textbf{R}.
	\item All connectioons may be excitatory or inhibitory.
\end{itemize}

Rosenblatt's perception model can then be further simplified:
\paragraph{Simplified perceptron model}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{simplified_perceptron_model}
\end{figure}

\begin{itemize}
	\item Association units commbine sensory input with fixed weights.
	\item Response units combine associative units with learnable weights.
\end{itemize}

Each of the units can be perceived as shown below:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{perceptron_fbd}
\end{figure}

\begin{itemize}
	\item Number of inputs combine linearly.
	\item Threshold logic is applied at the output of the unit: It will only fire if the weighted sum of the input exceeds threshold.
\end{itemize}

\[ 
Y = 
\begin{cases} 
	1, & \text{if } \sum_{i}w_ix_i - T >\ 0 \\
	0, & \text{else }
\end{cases}
\]

\subsection{The Universal Model}
Originally assumed could represent any Boolean circuit and perform any logic. However this was not true and this cause the research in neural networks died down because of the overhype. However, Rosenblatt was right, he not only gave us basic model, he also gives us the learning algorithm.

\[ w = w + \eta (d(x) - y(x))x \]

Sequential learning:
\begin{itemize}
	\item $d(x)$ is the desired output in response to input $x$.
	\item $y(x)$ is the actual output in response to $x$.
	\item Weight parameter is changed when the actual response of the neuron does not match the desired response of the neuron.
	\item If the actual response of the neuron exceeds the desired response of the neeuron, then the weight will decrease.
	\item If the actual response is lesser than the desired response, the weight will increase.
\end{itemize}
